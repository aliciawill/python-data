{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# sklearn 모델의 동일한 결과 출력을 위해 선언합니다.\n",
    "import numpy as np\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## estimator, model, 알고리즘, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (1437,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 64), (360,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### single model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(\n",
    "    criterion='entropy', \n",
    "    max_depth=25,\n",
    "    random_state=35\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=100,\n",
    "    n_jobs=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(\n",
    "    C=0.1, \n",
    "    gamma=0.003,\n",
    "    kernel='rbf',\n",
    "    probability=True ##각 라벨링값으로 될 가능성 구해주세요.!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.fit(X_train, y_train)\n",
    "dtree_predicted = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "knn_predicted = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train, y_train)\n",
    "svm_predicted = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy========================\n",
      "dtree >>  0.8888888888888888\n",
      "knn >>  0.9388888888888889\n",
      "svm >>  0.8916666666666667\n"
     ]
    }
   ],
   "source": [
    "print('accuracy========================')\n",
    "print('dtree >> ', accuracy_score(y_test, dtree_predicted))\n",
    "print('knn >> ', accuracy_score(y_test, knn_predicted))\n",
    "print('svm >> ', accuracy_score(y_test, svm_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_proba = dtree.predict_proba(X_test)\n",
    "dtree_proba[[1, 50]]  #5일 확률이 제일 높음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(dtree_proba[:1]), np.argmin(dtree_proba[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(dtree_proba[50]), np.argmin(dtree_proba[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.88, 0.08, 0.  , 0.  , 0.  , 0.  , 0.03, 0.01],\n",
       "       [0.  , 0.01, 0.14, 0.74, 0.  , 0.  , 0.  , 0.03, 0.01, 0.07]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_proba = knn.predict_proba(X_test)\n",
    "knn_proba[[1, 50]] #5일 확률이 제일 높음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(knn_proba[:1]), np.argmin(knn_proba[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(knn_proba[50]), np.argmin(knn_proba[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00181807, 0.00234139, 0.93321693, 0.00230159, 0.00209669,\n",
       "        0.00780094, 0.00172921, 0.00387275, 0.04160402, 0.00321841],\n",
       "       [0.00272881, 0.00398771, 0.01073558, 0.95260563, 0.00309729,\n",
       "        0.00650571, 0.00212815, 0.00543154, 0.00853704, 0.00424253]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_proba = svm.predict_proba(X_test)\n",
    "svm_proba[[1, 50]]  #5일 확률이 제일 높음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(svm_proba[:1]), np.argmin(svm_proba[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(svm_proba[50]), np.argmin(svm_proba[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 앙상블 모델 ##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 하드 보팅\n",
    "voting_clf1 = VotingClassifier(\n",
    "    estimators= [\n",
    "        ('decision tree', dtree), \n",
    "        ('knn', knn), \n",
    "        ('svm', svm)\n",
    "    ],\n",
    "    weights=[1, 1, 1],\n",
    "    voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9527777777777777"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf1.fit(X_train, y_train)\n",
    "hard_voting_predicted = voting_clf1.predict(X_test)\n",
    "accuracy_score(y_test, hard_voting_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dtree : 2, knn : 2, svm : 1==> 2(2): 1(1) ==> 다수결의 원칙에 따라 2로 판단!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_voting_predicted[[1, 50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 소프트 보팅\n",
    "voting_clf2 = VotingClassifier(\n",
    "    estimators= [\n",
    "        ('decision tree', dtree), \n",
    "        ('knn', knn), \n",
    "        ('svm', svm)\n",
    "    ],\n",
    "    weights=[1, 1, 1],\n",
    "    voting='soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf2.fit(X_train, y_train)\n",
    "soft_voting_predicted = voting_clf2.predict(X_test)\n",
    "accuracy_score(y_test, soft_voting_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 그래프로 그려보세요. accuracy(dtree, knn, svm, hard voting, soft voting)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.arange(5)\n",
    "plt.bar(x, height= [accuracy_score(y_test, dtree_predicted),\n",
    "                    accuracy_score(y_test, knn_predicted),\n",
    "                    accuracy_score(y_test, svm_predicted),\n",
    "                    accuracy_score(y_test, hard_voting_predicted),\n",
    "                    accuracy_score(y_test, soft_voting_predicted)])\n",
    "plt.xticks(x, ['decision tree','knn','svm','hard voting','soft voting']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
